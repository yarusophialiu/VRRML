import os 
import csv
import math
import torch
import onnx
import torchvision
# import seaborn as sns
import matplotlib.pyplot as plt
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data.dataloader import DataLoader
from torch.utils.data import random_split
from torchvision.utils import make_grid
from torch.utils.data import Dataset

from datetime import datetime
import torch.nn as nn
import numpy as np
# import torch.nn.functional as F
# from PIL import Image
from JOD import *
import onnx
from ignite.engine import *
from ignite.metrics import *




# # local pc
# CVVDPDIR = 'C:/Users/15142/Projects/ColorVideoVDP'
# VRRMP4_CVVDP = r'C:\Users\15142\Projects\VRR\VRRMP4_CVVDP'
# VRRDATA = 'C:/Users/15142/Projects/VRR/Data'
# VRR_Patches = f'{VRRDATA}/VRR_Patches'
# VRR_Motion = r'C:\Users\15142\Projects\VRR\VRR_Motion'
VRRML = f'C:/Users/15142/Projects/VRR/Data/VRRML'
VRRML_Project = r'C:\Users\15142\Projects\VRR\VRRML'
# VRRMP4_reference = r'C:\Users\15142\Projects\VRR\VRRMP4\uploaded\reference'

# # iron
# VRRML = r'/anfs/gfxdisp/quality_datasets/VRR/VRRML'

# windows titanium
# VRRML = r'D:\VRR_data\VRRML'
# VRRML_Project = r'D:\VRRML\VRRML'

scene_arr = ['bedroom', 'bistro', 
             'crytek_sponza', 'gallery', 
             'living_room', 'room', 
             'lost_empire', 'sibenik', 
             'suntemple', 
             'suntemple_statue']

refresh_rate = [30, 40, 50, 60, 70, 80, 90, 100, 110, 120]

fps_map = {30: 0, 40: 1, 50: 2, 60: 3, 70: 4, 80: 5, 90: 6, 100: 7, 110: 8, 120: 9}
res_map = {360: 0, 480: 1, 720: 2, 864: 3, 1080: 4}
bitrate_map = {500: 0.0, 1000: 0.333, 1500: 0.667, 2000: 1.0}

reverse_fps_map = {0: 30, 1: 40, 2: 50, 3: 60, 4: 70, 5: 80, 6: 90, 7: 100, 8: 110, 9: 120}
reverse_res_map = {0: 360, 1: 480, 2: 720, 3: 864, 4: 1080}


bistro_max_comb_per_sequence = {'path1_seg1_1': [[30, 1080], [40, 1080], [50, 1080], [50, 1080]], 'path1_seg1_2': [[70, 720], [80, 720], [80, 1080], [80, 1080]], 'path1_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[50, 720], [70, 1080], [80, 1080], [80, 1080]], 'path1_seg2_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[50, 720], [50, 1080], [50, 1080], [60, 1080]], 'path1_seg3_2': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path1_seg3_3': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[60, 720], [80, 720], [80, 720], [80, 1080]], 'path2_seg1_2': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path2_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[60, 720], [80, 720], [80, 1080], [80, 1080]], 'path2_seg2_2': [[90, 480], [110, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[120, 360], [120, 480], [120, 480], [120, 720]], 'path2_seg3_1': [[40, 720], [50, 1080], [60, 1080], [60, 1080]], 'path2_seg3_2': [[80, 720], [90, 720], [110, 720], [120, 720]], 'path2_seg3_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[90, 720], [100, 720], [110, 720], [120, 720]], 'path3_seg1_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path3_seg2_2': [[80, 720], [100, 720], [110, 720], [120, 720]], 'path3_seg2_3': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[80, 720], [90, 720], [110, 720], [120, 1080]], 'path3_seg3_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg3_3': [[120, 480], [120, 480], [120, 480], [120, 720]], 'path4_seg1_1': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path4_seg1_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path4_seg2_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_3': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg3_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg3_3': [[120, 360], [120, 480], [120, 480], [120, 480]], 'path5_seg1_1': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path5_seg1_2': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path5_seg1_3': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[80, 720], [90, 720], [120, 720], [120, 720]], 'path5_seg2_2': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg3_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]]}
room_max_comb_per_sequence = {'path1_seg1_1': [[60, 720], [70, 720], [90, 720], [110, 720]], 'path1_seg1_2': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path1_seg2_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[120, 360], [120, 360], [120, 360], [120, 360]], 'path1_seg3_2': [[120, 480], [120, 360], [120, 360], [120, 360]], 'path1_seg3_3': [[120, 360], [120, 480], [120, 360], [120, 360]], 'path2_seg1_1': [[60, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg1_2': [[80, 720], [110, 720], [110, 720], [120, 720]], 'path2_seg1_3': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path2_seg2_2': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[110, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg3_1': [[60, 720], [70, 720], [80, 720], [90, 720]], 'path2_seg3_2': [[70, 720], [80, 720], [80, 720], [110, 720]], 'path2_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[60, 720], [100, 720], [100, 720], [110, 720]], 'path3_seg1_2': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path3_seg1_3': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path3_seg2_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg3_2': [[80, 720], [90, 720], [120, 720], [120, 720]], 'path3_seg3_3': [[100, 720], [100, 720], [100, 720], [100, 720]], 'path4_seg1_1': [[110, 720], [110, 720], [110, 720], [120, 720]], 'path4_seg1_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[80, 720], [90, 720], [120, 720], [120, 720]], 'path4_seg3_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_1': [[70, 720], [80, 720], [110, 720], [110, 720]], 'path5_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path5_seg2_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[80, 720], [110, 720], [110, 720], [90, 1080]], 'path5_seg3_2': [[100, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]]}
bedroom_max_comb_per_sequence = {'path1_seg1_1': [[30, 720], [40, 720], [50, 720], [40, 1080]], 'path1_seg1_2': [[50, 720], [60, 720], [70, 720], [70, 720]], 'path1_seg1_3': [[60, 720], [80, 720], [80, 720], [80, 720]], 'path1_seg2_1': [[40, 720], [50, 720], [60, 720], [80, 720]], 'path1_seg2_2': [[60, 720], [60, 720], [80, 720], [100, 720]], 'path1_seg2_3': [[70, 720], [80, 720], [110, 720], [110, 720]], 'path1_seg3_1': [[50, 720], [60, 720], [110, 720], [110, 720]], 'path1_seg3_2': [[60, 720], [70, 720], [110, 720], [110, 720]], 'path1_seg3_3': [[80, 720], [80, 720], [90, 720], [90, 720]], 'path2_seg1_1': [[40, 720], [60, 720], [90, 720], [110, 720]], 'path2_seg1_2': [[50, 720], [60, 720], [80, 720], [110, 720]], 'path2_seg1_3': [[60, 720], [80, 720], [90, 720], [90, 720]], 'path2_seg2_1': [[50, 720], [60, 720], [80, 720], [80, 720]], 'path2_seg2_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[100, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[40, 720], [60, 720], [80, 720], [80, 720]], 'path2_seg3_2': [[60, 720], [80, 720], [110, 720], [120, 720]], 'path2_seg3_3': [[60, 480], [80, 720], [90, 720], [110, 720]], 'path3_seg1_1': [[40, 720], [50, 720], [70, 720], [80, 720]], 'path3_seg1_2': [[50, 720], [80, 720], [80, 720], [90, 720]], 'path3_seg1_3': [[60, 720], [70, 720], [80, 720], [90, 720]], 'path3_seg2_1': [[30, 720], [50, 720], [60, 720], [70, 720]], 'path3_seg2_2': [[50, 720], [60, 720], [70, 720], [80, 720]], 'path3_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[60, 720], [80, 720], [90, 720], [110, 720]], 'path3_seg3_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg3_3': [[110, 480], [110, 720], [110, 720], [110, 720]], 'path4_seg1_1': [[60, 720], [80, 720], [80, 720], [80, 720]], 'path4_seg1_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path4_seg1_3': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path4_seg2_2': [[90, 720], [100, 720], [120, 720], [120, 720]], 'path4_seg2_3': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[120, 480], [120, 480], [120, 720], [120, 720]], 'path4_seg3_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg3_3': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg1_1': [[60, 720], [80, 720], [110, 720], [110, 720]], 'path5_seg1_2': [[90, 720], [90, 720], [110, 720], [120, 720]], 'path5_seg1_3': [[60, 720], [90, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[40, 720], [50, 720], [60, 720], [60, 720]], 'path5_seg2_2': [[70, 720], [80, 720], [110, 720], [110, 720]], 'path5_seg2_3': [[110, 480], [110, 720], [110, 720], [110, 720]], 'path5_seg3_1': [[60, 720], [80, 720], [80, 720], [110, 720]], 'path5_seg3_2': [[80, 720], [90, 720], [110, 720], [120, 720]], 'path5_seg3_3': [[110, 480], [110, 720], [110, 720], [110, 720]]}
crytek_sponza_max_comb_per_sequence = {'path1_seg1_1': [[60, 720], [70, 1080], [80, 1080], [80, 1080]], 'path1_seg1_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[100, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[50, 720], [40, 1080], [50, 1080], [60, 1080]], 'path1_seg2_2': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path1_seg2_3': [[80, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[50, 720], [40, 1080], [50, 1080], [50, 1080]], 'path1_seg3_2': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path1_seg3_3': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[30, 720], [40, 1080], [40, 1080], [50, 1080]], 'path2_seg1_2': [[80, 720], [80, 720], [90, 720], [90, 720]], 'path2_seg1_3': [[80, 480], [90, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[30, 720], [40, 1080], [40, 1080], [40, 1080]], 'path2_seg2_2': [[60, 720], [70, 720], [80, 720], [80, 720]], 'path2_seg2_3': [[70, 720], [80, 720], [90, 720], [90, 720]], 'path2_seg3_1': [[40, 720], [50, 720], [60, 720], [50, 1080]], 'path2_seg3_2': [[80, 720], [80, 720], [90, 720], [110, 720]], 'path2_seg3_3': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[30, 720], [50, 720], [60, 720], [60, 720]], 'path3_seg1_2': [[80, 720], [80, 720], [90, 720], [110, 720]], 'path3_seg1_3': [[80, 720], [100, 720], [110, 720], [120, 720]], 'path3_seg2_1': [[40, 720], [50, 720], [60, 720], [50, 1080]], 'path3_seg2_2': [[60, 720], [70, 720], [80, 720], [80, 720]], 'path3_seg2_3': [[80, 720], [90, 720], [90, 720], [110, 720]], 'path3_seg3_1': [[40, 720], [60, 720], [70, 720], [50, 1080]], 'path3_seg3_2': [[60, 720], [70, 720], [80, 720], [110, 720]], 'path3_seg3_3': [[70, 720], [80, 720], [90, 720], [110, 720]], 'path4_seg1_1': [[30, 720], [30, 1080], [30, 1080], [30, 1080]], 'path4_seg1_2': [[40, 720], [50, 720], [40, 1080], [50, 1080]], 'path4_seg1_3': [[50, 720], [50, 720], [60, 720], [60, 720]], 'path4_seg2_1': [[30, 720], [40, 720], [30, 1080], [30, 1080]], 'path4_seg2_2': [[30, 720], [50, 720], [50, 720], [40, 1080]], 'path4_seg2_3': [[40, 720], [50, 720], [60, 720], [70, 720]], 'path4_seg3_1': [[30, 720], [30, 1080], [30, 1080], [30, 1080]], 'path4_seg3_2': [[40, 720], [50, 720], [40, 1080], [50, 1080]], 'path4_seg3_3': [[40, 720], [60, 720], [50, 1080], [60, 1080]], 'path5_seg1_1': [[30, 720], [40, 1080], [40, 1080], [50, 1080]], 'path5_seg1_2': [[60, 720], [80, 720], [90, 720], [100, 720]], 'path5_seg1_3': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path5_seg2_1': [[50, 720], [60, 720], [70, 720], [60, 1080]], 'path5_seg2_2': [[80, 480], [90, 720], [110, 720], [110, 720]], 'path5_seg2_3': [[80, 480], [90, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[60, 720], [80, 720], [90, 720], [90, 720]], 'path5_seg3_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[110, 480], [110, 480], [120, 720], [120, 720]]}
gallery_max_comb_per_sequence = {'path1_seg1_1': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[80, 720], [100, 720], [110, 720], [120, 1080]], 'path1_seg2_2': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[100, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[80, 720], [80, 720], [90, 1080], [90, 1080]], 'path1_seg3_2': [[90, 720], [90, 720], [110, 720], [120, 864]], 'path1_seg3_3': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[50, 720], [50, 864], [60, 1080], [70, 1080]], 'path2_seg1_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg1_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[60, 720], [60, 720], [70, 864], [80, 1080]], 'path2_seg2_2': [[80, 480], [90, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg3_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[120, 360], [120, 480], [120, 720], [120, 720]], 'path3_seg1_1': [[80, 480], [90, 720], [110, 720], [120, 720]], 'path3_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[50, 720], [80, 720], [80, 1080], [80, 1080]], 'path3_seg2_2': [[70, 720], [80, 720], [110, 720], [120, 864]], 'path3_seg2_3': [[70, 720], [90, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[50, 720], [60, 1080], [60, 1080], [70, 1080]], 'path3_seg3_2': [[80, 720], [80, 720], [110, 720], [110, 1080]], 'path3_seg3_3': [[80, 720], [80, 720], [120, 720], [120, 720]], 'path4_seg1_1': [[60, 720], [70, 720], [80, 720], [80, 720]], 'path4_seg1_2': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path4_seg1_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_2': [[120, 480], [120, 480], [120, 480], [120, 720]], 'path4_seg2_3': [[120, 360], [120, 480], [120, 480], [120, 480]], 'path4_seg3_1': [[50, 720], [70, 720], [80, 720], [80, 720]], 'path4_seg3_2': [[110, 480], [120, 480], [120, 720], [120, 720]], 'path4_seg3_3': [[120, 360], [120, 480], [120, 480], [120, 480]], 'path5_seg1_1': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[60, 720], [80, 720], [80, 720], [110, 720]], 'path5_seg2_2': [[80, 720], [90, 720], [120, 720], [110, 1080]], 'path5_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path5_seg3_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]]}
living_room_max_comb_per_sequence = {'path1_seg1_1': [[90, 720], [110, 720], [120, 864], [120, 864]], 'path1_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[120, 480], [120, 480], [120, 720], [120, 720]], 'path1_seg2_1': [[110, 720], [110, 720], [110, 720], [110, 720]], 'path1_seg2_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[90, 720], [110, 720], [110, 1080], [120, 1080]], 'path1_seg3_2': [[100, 720], [120, 720], [120, 864], [120, 864]], 'path1_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg1_2': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path2_seg1_3': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg2_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[80, 720], [110, 720], [120, 1080], [120, 1080]], 'path2_seg3_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[110, 720], [110, 720], [110, 720], [110, 720]], 'path3_seg1_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path3_seg2_2': [[120, 360], [120, 480], [120, 480], [120, 720]], 'path3_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path3_seg3_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg1_1': [[110, 720], [110, 720], [110, 720], [110, 720]], 'path4_seg1_2': [[110, 720], [110, 720], [110, 720], [120, 720]], 'path4_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[60, 720], [60, 1080], [80, 1080], [80, 1080]], 'path4_seg2_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[80, 720], [100, 720], [120, 1080], [120, 1080]], 'path4_seg3_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_1': [[70, 720], [80, 720], [110, 720], [110, 720]], 'path5_seg1_2': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path5_seg1_3': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path5_seg2_1': [[80, 720], [110, 720], [110, 720], [110, 1080]], 'path5_seg2_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_3': [[120, 360], [120, 480], [120, 720], [120, 720]], 'path5_seg3_1': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path5_seg3_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]]}
lost_empire_max_comb_per_sequence = {'path1_seg1_1': [[50, 720], [60, 720], [60, 720], [60, 1080]], 'path1_seg1_2': [[70, 720], [80, 720], [80, 720], [90, 720]], 'path1_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_2': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[70, 720], [90, 720], [110, 720], [110, 720]], 'path2_seg1_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[70, 720], [90, 720], [110, 720], [110, 720]], 'path2_seg2_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[70, 720], [90, 720], [110, 720], [110, 720]], 'path2_seg3_2': [[100, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[90, 720], [100, 720], [110, 720], [120, 720]], 'path3_seg1_2': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[50, 720], [80, 720], [90, 720], [120, 720]], 'path3_seg2_2': [[80, 720], [90, 720], [110, 720], [110, 864]], 'path3_seg2_3': [[110, 480], [110, 720], [110, 720], [110, 720]], 'path3_seg3_1': [[40, 720], [50, 1080], [60, 1080], [60, 1080]], 'path3_seg3_2': [[40, 720], [50, 1080], [60, 1080], [60, 1080]], 'path3_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg1_1': [[50, 720], [60, 720], [80, 720], [80, 720]], 'path4_seg1_2': [[80, 720], [90, 720], [110, 720], [110, 720]], 'path4_seg1_3': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[50, 720], [80, 720], [80, 720], [80, 1080]], 'path4_seg2_2': [[70, 720], [90, 720], [110, 720], [120, 720]], 'path4_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[60, 720], [70, 720], [80, 720], [80, 1080]], 'path4_seg3_2': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path4_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg1_1': [[80, 480], [80, 720], [100, 720], [120, 720]], 'path5_seg1_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg1_3': [[120, 480], [120, 480], [120, 720], [120, 720]], 'path5_seg2_1': [[70, 720], [80, 720], [80, 720], [90, 720]], 'path5_seg2_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_3': [[120, 360], [120, 480], [120, 720], [120, 720]], 'path5_seg3_1': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_2': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path5_seg3_3': [[120, 360], [120, 480], [120, 480], [120, 480]]}
sibenik_max_comb_per_sequence = {'path1_seg1_1': [[80, 720], [90, 720], [120, 720], [120, 720]], 'path1_seg1_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[80, 720], [110, 720], [110, 720], [120, 720]], 'path1_seg2_2': [[100, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[50, 720], [70, 1080], [80, 1080], [80, 1080]], 'path1_seg3_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path1_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[50, 720], [50, 1080], [60, 1080], [70, 1080]], 'path2_seg1_2': [[80, 720], [90, 720], [110, 720], [120, 720]], 'path2_seg1_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[50, 720], [60, 720], [70, 864], [80, 1080]], 'path2_seg2_2': [[90, 720], [110, 720], [110, 720], [120, 720]], 'path2_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[60, 720], [80, 720], [110, 720], [110, 720]], 'path2_seg3_2': [[90, 480], [110, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[50, 720], [60, 864], [80, 1080], [80, 1080]], 'path3_seg1_2': [[80, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[110, 480], [110, 720], [120, 720], [120, 720]], 'path3_seg2_1': [[60, 720], [80, 720], [80, 1080], [90, 1080]], 'path3_seg2_2': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg2_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[80, 720], [80, 720], [110, 720], [120, 1080]], 'path3_seg3_2': [[110, 480], [120, 480], [120, 720], [120, 720]], 'path3_seg3_3': [[120, 360], [120, 480], [120, 720], [120, 720]], 'path4_seg1_1': [[90, 720], [110, 720], [120, 720], [120, 720]], 'path4_seg1_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path4_seg2_2': [[120, 480], [120, 480], [120, 720], [120, 720]], 'path4_seg2_3': [[120, 480], [120, 480], [120, 720], [120, 720]], 'path4_seg3_1': [[70, 720], [90, 720], [100, 720], [120, 720]], 'path4_seg3_2': [[120, 360], [120, 480], [120, 720], [120, 720]], 'path4_seg3_3': [[120, 480], [120, 480], [120, 480], [120, 480]], 'path5_seg1_1': [[80, 720], [80, 720], [100, 720], [100, 1080]], 'path5_seg1_2': [[110, 720], [110, 720], [120, 720], [120, 1080]], 'path5_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[50, 720], [60, 720], [80, 720], [80, 1080]], 'path5_seg2_2': [[80, 720], [90, 720], [110, 720], [120, 720]], 'path5_seg2_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path5_seg3_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 480], [120, 480], [120, 720], [120, 720]]}
suntemple_max_comb_per_sequence = {'path1_seg1_1': [[50, 720], [60, 720], [60, 1080], [60, 1080]], 'path1_seg1_2': [[60, 720], [70, 720], [80, 720], [80, 720]], 'path1_seg1_3': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[40, 720], [60, 720], [60, 1080], [60, 1080]], 'path1_seg2_2': [[60, 720], [80, 720], [120, 720], [120, 720]], 'path1_seg2_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path1_seg3_1': [[50, 720], [60, 720], [80, 720], [80, 720]], 'path1_seg3_2': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path1_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[40, 720], [50, 720], [60, 720], [60, 720]], 'path2_seg1_2': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg1_3': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg2_1': [[40, 720], [60, 720], [70, 720], [80, 720]], 'path2_seg2_2': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[60, 720], [70, 720], [80, 720], [110, 720]], 'path2_seg3_2': [[80, 720], [110, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[80, 720], [90, 720], [120, 720], [120, 720]], 'path3_seg1_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_3': [[80, 480], [120, 480], [110, 720], [120, 720]], 'path3_seg2_1': [[70, 720], [80, 720], [80, 720], [110, 720]], 'path3_seg2_2': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg2_3': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[60, 720], [70, 720], [80, 720], [100, 720]], 'path3_seg3_2': [[60, 720], [80, 720], [110, 720], [120, 720]], 'path3_seg3_3': [[110, 720], [110, 720], [120, 720], [120, 720]], 'path4_seg1_1': [[70, 720], [90, 720], [90, 720], [110, 720]], 'path4_seg1_2': [[90, 720], [90, 720], [100, 720], [110, 720]], 'path4_seg1_3': [[90, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[50, 720], [50, 720], [60, 720], [70, 720]], 'path4_seg2_2': [[60, 720], [80, 720], [80, 720], [80, 720]], 'path4_seg2_3': [[70, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[60, 720], [80, 720], [110, 720], [80, 1080]], 'path4_seg3_2': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path4_seg3_3': [[90, 720], [110, 720], [110, 720], [120, 720]], 'path5_seg1_1': [[80, 720], [110, 720], [110, 1080], [110, 1080]], 'path5_seg1_2': [[120, 720], [120, 720], [120, 1080], [120, 1080]], 'path5_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[80, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg2_2': [[90, 480], [90, 720], [90, 720], [90, 720]], 'path5_seg2_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_2': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[110, 480], [110, 720], [110, 720], [110, 720]]}
suntemple_statue_max_comb_per_sequence = {'path1_seg1_1': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg1_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path1_seg2_1': [[80, 720], [100, 720], [110, 720], [110, 1080]], 'path1_seg2_2': [[110, 720], [110, 720], [120, 1080], [120, 1080]], 'path1_seg2_3': [[110, 720], [110, 720], [110, 1080], [110, 1080]], 'path1_seg3_1': [[50, 720], [60, 1080], [60, 1080], [80, 1080]], 'path1_seg3_2': [[80, 720], [110, 720], [110, 1080], [110, 1080]], 'path1_seg3_3': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg1_1': [[50, 720], [50, 1080], [60, 1080], [80, 1080]], 'path2_seg1_2': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg1_3': [[110, 480], [120, 480], [120, 720], [120, 720]], 'path2_seg2_1': [[50, 720], [60, 864], [80, 1080], [80, 1080]], 'path2_seg2_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg2_3': [[110, 480], [120, 720], [120, 720], [120, 720]], 'path2_seg3_1': [[80, 720], [110, 720], [110, 720], [110, 720]], 'path2_seg3_2': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path2_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path3_seg1_1': [[40, 720], [50, 1080], [50, 1080], [60, 1080]], 'path3_seg1_2': [[80, 720], [80, 720], [110, 720], [110, 720]], 'path3_seg1_3': [[90, 720], [110, 720], [110, 720], [110, 720]], 'path3_seg2_1': [[80, 720], [110, 864], [110, 864], [110, 1080]], 'path3_seg2_2': [[70, 720], [110, 864], [120, 1080], [120, 1080]], 'path3_seg2_3': [[90, 720], [90, 720], [120, 720], [120, 720]], 'path3_seg3_1': [[70, 720], [60, 1080], [80, 1080], [80, 1080]], 'path3_seg3_2': [[80, 720], [110, 720], [110, 864], [120, 864]], 'path3_seg3_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg1_1': [[90, 720], [110, 720], [110, 720], [110, 1080]], 'path4_seg1_2': [[120, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path4_seg2_1': [[110, 720], [110, 720], [110, 720], [110, 720]], 'path4_seg2_2': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg2_3': [[90, 720], [120, 720], [120, 720], [120, 720]], 'path4_seg3_1': [[40, 864], [40, 1080], [60, 1080], [80, 1080]], 'path4_seg3_2': [[60, 864], [70, 1080], [80, 1080], [80, 1080]], 'path4_seg3_3': [[100, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg1_1': [[40, 1080], [60, 1080], [60, 1080], [80, 1080]], 'path5_seg1_2': [[120, 720], [120, 720], [120, 1080], [120, 1080]], 'path5_seg1_3': [[120, 480], [120, 720], [120, 720], [120, 720]], 'path5_seg2_1': [[70, 1080], [80, 1080], [80, 1080], [80, 1080]], 'path5_seg2_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg2_3': [[120, 480], [110, 720], [120, 720], [120, 720]], 'path5_seg3_1': [[70, 720], [80, 720], [110, 720], [110, 1080]], 'path5_seg3_2': [[110, 720], [120, 720], [120, 720], [120, 720]], 'path5_seg3_3': [[120, 720], [120, 720], [120, 720], [120, 720]]}


transform_resize = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize if needed
    transforms.ToTensor(),
])

transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
])

def get_velocities_from_patch_data(folder):
    velocities = []
    with open(folder, mode='r') as file:
        reader = csv.reader(file)
        for row in reader:
            velocities.append(float(row[0]))
    return velocities

def count_files_in_folder(folder_path):
    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])


def get_jod_score(all_data, sheet_name, bitrate, fps, resolution):
    """
    Retrieves a JOD score from the nested dictionary using the specified sheet name, bitrate, fps, and resolution.
    Returns 'Not Found' if any key is missing.
    """
    # print(type(all_data))
    # print(type(bitrate))
    # print(type(fps))
    # print(type(resolution))
    return all_data.get(sheet_name, {}).get(bitrate, {}).get(fps, {}).get(resolution, "Not Found")



def denormalize(normalized_value, min_val=0, max_val=276):
    original_value = normalized_value * (max_val - min_val) + min_val
    return original_value


def show_patch(patch):
    plt.imshow(patch)
    plt.axis('off')  # Hide axis
    plt.show()



def mapIdToPath(id):
    """
    we run 15 jobs/tasks (allocate 13 gpus) at one time, each scene has 45 clips, so we run 3 times
    for each task id, we run videos for 1 scene, 1 seg, 1 speed, i.e. for loop 50 * 13 = 650 videos
    e.g. sbatch --array=0-14:1 -A STARS-SL3-GPU submission_script

    id is from 0-44, map id -> path, seg, speed

    e.g. id 0 -> paths[0], segs[0], speeds[0]
         id 1 -> paths[0], segs[0], speeds[1]
    """
    pathIdx = int(math.floor(id/9))
    segIdx = int(math.floor((id - pathIdx * 9) / 3))
    speedIdx = (id - pathIdx * 9) % 3
    paths = [1, 2, 3, 4, 5]
    segs = [1, 2, 3,]
    speeds = [1, 2, 3,]
    # print(f'pathIdx {pathIdx}, segIdx {segIdx} speedIdx {speedIdx}')
    print(f'path, seg, speeds {paths[pathIdx], segs[segIdx], speeds[speedIdx]}')
    return paths[pathIdx], segs[segIdx], speeds[speedIdx]



def mapPathToId(path, seg, speed):
    id = (path-1) * 9 + (seg-1) * 3 + speed - 1
    # print(f'id {id}')
    return id






def minMaxNormalizer(feature_tensor):
    """Takes the Torch.tensor object containing the features and performs min-max normalization on the Torch.tensor.
    The function iterates through each column and performs scaling on them individually.
    
    Args-
        feature_tensor- Tensor containing training features
    """
    # print(f'feature_tensor \n {feature_tensor.size()}')
    total_cols = feature_tensor.size()[1] # total unmber of columns 
    # print(f'total_cols {total_cols}')

    normalized_feature_tensor = torch.zeros_like(feature_tensor)

    # total_cols-2 to skip fps and bps, when fps and bps are the same, result is nan
    for i in range(total_cols): # iterating through each column
        feature_col = feature_tensor[:, i]
        # print(f'feature_col {feature_col}')

        maximum = torch.max(feature_col) # maximum stores max value of the column
        minimum = torch.min(feature_col) # minimum stores min value of the column
        scaled_feature_col = (feature_col - minimum) / (maximum - minimum)
        # scaled_feature_col = feature_col

        normalized_feature_tensor[:, i] = scaled_feature_col # min-max scalinng of each element of the column
        # print(f'feature_tensor[:, i] {feature_tensor[:, i]}')

        # if i == 33:
        #     print(f'max min {maximum, minimum}')
        #     print(f'feature_col {feature_col}')
        #     print(f'scaled_feature_col {scaled_feature_col}')
    return normalized_feature_tensor


def get_default_device():
    """ Set Device to GPU or CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    

def to_device(data, device):
    "Move data to the device"
    if isinstance(data,(list,tuple)):
        return [to_device(x,device) if not isinstance(x, str) else x for x in data]
    # non_blocking speeds up data transfers to the GPU by allowing asynchronous data movement
    # print(f'data {type(data)} {data}')
    return data.to(device, non_blocking = True)


def r2_score(target, prediction):
    """Calculates the r2 score of the model"""
    r2 = 1- torch.sum((target-prediction)**2) / torch.sum((target-target.float().mean())**2)
    return r2


def save_checkpoint(model, optimizer, save_path, epoch):
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'epoch': epoch
    }, save_path)


def load_checkpoint(model, optimizer, load_path):
    checkpoint = torch.load(load_path)
    print("Keys in the checkpoint:", checkpoint.keys())
    model.load_state_dict(checkpoint['model_state_dict'])
    if 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    else:
        print("No optimizer state found in checkpoint!")

    # Load the epoch number
    epoch = checkpoint.get('epoch', None)
    
    return model, optimizer, epoch



def plot_accuracy_curve(accuracies):

    plt.figure(figsize=(10, 5))
    sns.lineplot(x=range(len(accuracies)), y=accuracies, marker='o', label='Accuracy')

    plt.title("Accuracy Curve Over Time")
    plt.xlabel("Epochs / Iterations")
    plt.ylabel("Accuracy (%)")
    plt.legend()
    plt.show()



def zscore_normalization_reverse(sample, data):
    mean = np.mean(data)
    std_dev = np.std(data)
    original_sample = sample * std_dev + mean
    return round(original_sample, 3)


def count_parameters_onnx(onnx_model_path):
    model = onnx.load(onnx_model_path)
    total_params = 0

    # Iterate through the model's initializer (parameters)
    for initializer in model.graph.initializer:
        # Get the parameter shape
        param_shape = tuple(dim for dim in initializer.dims)
        # Calculate the number of parameters for this tensor
        num_params = np.prod(param_shape)
        total_params += num_params

    return total_params


def compute_weighted_loss(res_out, fps_out, res_targets, fps_targets):
    loss_fn_res = nn.CrossEntropyLoss() # CrossEntropyLoss internally apply softmax to logits and calculates the loss
    loss_fn_fps = nn.CrossEntropyLoss()
    # print(f'res_targets {res_targets.long().dtype}')
    # print(f'res_out {res_out}， res_targets {res_targets}')
    # print(f'fps_targets {fps_targets.dtype}')
    loss_res = loss_fn_res(res_out, res_targets) # .type(torch.LongTensor).to(torch.device('cuda')))
    loss_fps = loss_fn_fps(fps_out, fps_targets) # .type(torch.LongTensor).to(torch.device('cuda')))
    total_loss = loss_res + loss_fps
    total_loss = loss_res + loss_fps
    # print(f'total_loss {total_loss}\n')

    return total_loss


def find_key_by_value(dictionary, target_value):
    # Loop through dictionary items
    for key, value in dictionary.items():
        if value == target_value:
            return key
    return None  # Return None if the value is not found


def compute_JOD_loss(path, bitrate, fps_preds, res_preds, fps_targets, res_targets):
    # for i in range(fps_targets.size()[0]):
    base_name = path.split('_path')[0]  # e.g., "crytek_sponza", "bistro", "gallery"
    # print(f'\npath {path}, base_name {base_name}')

    start_idx = path.find('path')
    path_name = path[start_idx:]
    # path_name = '_'.join(path.split('_')[1:])
    variable_name = f"{base_name}_jod"
    if variable_name in globals():
        corresponding_value = globals()[variable_name]
        fps_preds_val = find_key_by_value(fps_map, fps_preds)
        res_preds_val = find_key_by_value(res_map, res_preds)
        fps_targets_val = find_key_by_value(fps_map, fps_targets)
        res_targets_val = find_key_by_value(res_map, res_targets)
        bitrate_val = find_key_by_value(bitrate_map, round(bitrate, 3))

        print(f"corresponding_value {corresponding_value}")
        print(f"{variable_name} fps, res preds {fps_preds_val, res_preds_val}")
        # print(f"fps, res targets {fps_targets_val, res_targets_val}")
        print(f"path_name {path_name}, bitrate_val {bitrate_val}")
        pred = get_jod_score(corresponding_value, path_name, bitrate_val, fps_preds_val, str(res_preds_val))
        truth = get_jod_score(corresponding_value, path_name, bitrate_val, fps_targets_val, str(res_targets_val))
        # print(f'pred {pred}, truth {truth}')
        # return (pred - truth) ** 2
        return pred, truth
    else:
        # print(f"Variable {variable_name} does not exist")
        return 0, 0
    



def count_parameters(model_path, model_class=None):
    """
    Count the total number of parameters in a PyTorch model.
    
    Parameters:
        pth_model_path (str): Path to the .pth model file.
        model_class (torch.nn.Module, optional): The class definition of the model
            (only required if the saved file contains state_dict).
    
    Returns:
        int: Total number of parameters in the model.
    """
    # model_class = DecRefClassification(num_framerates=10, num_resolutions=5)

    state_dict = torch.load(model_path)
    model_class.load_state_dict(state_dict)
    total_params = sum(p.numel() for p in model_class.parameters())
    print(f"Total number of parameters in the model: {total_params}")
    return total_params

def count_parameters_onnx(onnx_model_path):
    # Load the ONNX model
    model = onnx.load(onnx_model_path)

    # Initialize parameter count
    total_params = 0

    # Iterate through the model's initializer (parameters)
    for initializer in model.graph.initializer:
        # Get the parameter shape
        param_shape = tuple(dim for dim in initializer.dims)
        # Calculate the number of parameters for this tensor
        num_params = np.prod(param_shape)
        total_params += num_params

    return total_params


def eval_step(engine, batch):
    return batch

def geometric_mean_relative_error(R_test, R_ref):
    """geometric mean"""
    metric = GeometricAverage()
    default_evaluator = Engine(eval_step)
    metric.attach(default_evaluator, 'avg')
    # Case 1. input is er
    data = torch.abs((R_test - R_ref) / R_ref)
    state = default_evaluator.run(data)
        
    return round(state.metrics['avg'], 4)



def compute_RMSE(predicted, target):
    """
    root mean square error
    https://help.pecan.ai/en/articles/6456388-model-performance-metrics-for-regression-models
    """
    predicted = predicted.float()
    target = target.float()
    mse = torch.mean((predicted - target) ** 2)  # Mean Squared Error
    rmse = torch.sqrt(mse)  # Root Mean Squared Error
    # print(f'mse, rmse {mse}, {rmse}')
    return round(rmse.item(), 3)


def compute_RMSEP(predicted, target):
    """
    Root Mean Squared Percentage Error (RMSPE)
    https://help.pecan.ai/en/articles/6456388-model-performance-metrics-for-regression-models
    """
    predicted = predicted.float()
    target = target.float()
    percentage_error = (predicted - target) / target
    squared_percentage_error = percentage_error ** 2
    rmspe = torch.sqrt(torch.mean(squared_percentage_error))

    # print(f"RMSPE: {rmspe.item() * 100:.2f}%")
    return round(rmspe.item() * 100, 3)

    
def compute_accuracy(fps_out, res_out, fps_targets, res_targets, bitrate=None, paths=None):
        # print(f'fps_out \n {}')
        _, fps_preds = torch.max(fps_out, dim=1)
        _, res_preds = torch.max(res_out, dim=1)

        framerate_accuracy = torch.tensor(torch.sum(fps_preds == fps_targets).item() / len(fps_targets))
        resolution_accuracy = torch.tensor(torch.sum(res_preds == res_targets).item() / len(res_targets))
        both_correct_accuracy = torch.tensor(torch.sum((res_preds == res_targets) & (fps_preds == fps_targets)).item() / len(res_targets))
        jod_preds_arr = []
        jod_targets_arr = []
        # jod_loss = 0
        # data_size = fps_targets.size()[0]
        data_size = len(fps_targets)
        if paths:
            for i in range(data_size):
                # print(f'path {paths[i]}')
                jod_preds, jod_targets =  compute_JOD_loss(paths[i], bitrate[i].item(), fps_preds[i].item(), res_preds[i].item(), fps_targets[i].item(), res_targets[i].item())
                jod_preds_arr.append(jod_preds)
                jod_targets_arr.append(jod_targets)
            # jod_loss /= data_size
            # jod_loss_arr.append(jod_loss)
            # print(f'jod_loss {jod_loss} data_size {data_size}')
        return framerate_accuracy, resolution_accuracy, both_correct_accuracy, torch.tensor(jod_preds_arr), torch.tensor(jod_targets_arr)
# torch.sqrt(torch.mean(torch.tensor(jod_loss_arr)))

def plot_test_result(test_dl, predictions, epoch="", SAVE_PLOT=False):
    for batch in test_dl:
        resolution = batch["resolution"]
        test_fps = batch["fps"]
        bitrate = batch["bitrate"]

        test_fps_np = test_fps.cpu().numpy()
        bitrate_np = bitrate.cpu().numpy()
        resolution_np = resolution.cpu().numpy()
        predictions_np = predictions.cpu().numpy()
        
        x_axis = [360, 480, 720, 864, 1080]
        bitrates_to_plot = [4000, 8000]

        fps_categories = {4000: [70, 80, 90], 8000: [70, 90, 150]}
        colors = ['green', 'orange', 'red']
        # colors = ['blue', 'greenyellow', 'red', 'green', 'orange',]
        true_labels_by_fps_8000 = {
            70: [4.799, 5.030, 5.137, 5.198, 5.253],
            90: [5.265, 5.529, 5.669, 5.731, 5.793],
            150: [5.800, 6.108, 6.237, 6.333, 6.439]
        }
        true_labels_by_fps_4000 = {
            70: [4.647, 4.867, 4.954, 5.001, 5.056],
            80: [4.748, 4.956, 5.026, 5.089, 5.158],
            90: [5.043, 5.299, 5.394, 5.451, 5.503]
        }

        true_labels_by_fps = {4000: true_labels_by_fps_4000, 8000: true_labels_by_fps_8000}

        for bitrate_to_plot in bitrates_to_plot:
            print(f'================= bitrate_to_plot {bitrate_to_plot} ================= ')

            indices_for_bitrate = (bitrate_np == bitrate_to_plot)
            predictions_for_bitrate = predictions_np[indices_for_bitrate]
            resolution_for_bitrate = resolution_np[indices_for_bitrate]
            fps_for_bitrate = test_fps_np[indices_for_bitrate]

            true_labels = true_labels_by_fps[bitrate_to_plot]

            plt.figure(figsize=(10, 6))
            for fps_val, color in zip(fps_categories[bitrate_to_plot], colors):
                # print(f'fps_val {fps_val, color}')
                indices_for_fps = (fps_for_bitrate == fps_val)
                resolution_for_fps = resolution_for_bitrate[indices_for_fps]
                labels_for_fps = predictions_for_bitrate[indices_for_fps]

                # print(f'indices_for_fps \n {indices_for_fps}')
                # print(f'resolution_for_fps \n {resolution_for_fps}')
                # print(f'labels_for_fps \n {labels_for_fps}')

                plt.plot(x_axis, true_labels[fps_val], color=color, linestyle='--', marker='^', label=f'True FPS {fps_val}')
                plt.scatter(resolution_for_fps, labels_for_fps, color=color, label=f'Predicted FPS {fps_val}')
    
                # fps_indices = (fps_for_bitrate == np.full_like(resolution_for_bitrate, fps_val))  # fix fps  
                # print(f'fps_indices \n {fps_indices}')
                
                # for res in x_axis:
                #     indices = fps_indices & (resolution_for_bitrate == res) # fix fps and resolution
                #     plt.scatter([res] * indices.sum(), predictions_for_bitrate[indices], color=color, alpha=0.7)

            plt.xticks(x_axis)
            plt.xlabel('Resolution')
            plt.ylabel('JOD')
            plt.title(f'True vs Predicted JOD Bitrate {bitrate_to_plot/1000} Mbps')
            plt.grid(True)
            plt.legend()

            if SAVE_PLOT:
                current_time = datetime.now().strftime("%m%d_%H%M_%S")
                plt.savefig(f"plots/{current_time}_{bitrate_to_plot}_{epoch}.png")
            plt.show()
            # plt.show(block = False)
            # plt.pause(1)
            plt.close('all')



def predict_img_class(img, fps, bitrate, model):
    """ Predict the class of image and Return Predicted Class"""
    img = to_device(img.unsqueeze(0), device)
    prediction = model(img, fps, bitrate)
    print(f'prediction {prediction}')
    # _, preds = torch.max(prediction, dim = 1)
    # return dataset.classes[preds[0].item()]
    return prediction


def show_patch(patch):
    plt.imshow(patch)
    plt.axis('off')  # Hide axis
    plt.show()



def display_img(img,label, dataset):
    print(f"Label : {dataset.classes[label]}")
    plt.imshow(img.permute(1,2,0))
    plt.show()


def show_batch(dl):
    """Plot images grid of single batch"""
    for batch in dl: # dl calls __getitem__
        images = batch["image"]
        print(f'images {images.dtype}')
        labels = batch["label"]
        print(f'Labels: {labels}')
        fig,ax = plt.subplots(figsize = (16,12))
        ax.set_xticks([])
        ax.set_yticks([])
        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))
        plt.show()
        break


# def display_img(img,label, dataset):
#     print(f"Label : {dataset.classes[label]}")
#     plt.imshow(img.permute(1,2,0))
#     plt.show()

# def show_batch(dl):
#     """Plot images grid of single batch"""
#     for batch in dl: # dl calls __getitem__
#         images = batch["image"]
#         print(f'images {images.dtype}')
#         labels = batch["label"]
#         print(f'Labels: {labels}')
#         fig,ax = plt.subplots(figsize = (16,12))
#         ax.set_xticks([])
#         ax.set_yticks([])
#         ax.imshow(make_grid(images,nrow=16).permute(1,2,0))
#         plt.show()
#         break



# def normalize_z_value(column, data):
def normalize_z_value(column, mean, std_dev):
    # mean = np.mean(data)
    # std_dev = np.std(data)
    return (column - mean) / std_dev


def unnormalize_z_value(normalized_column, mean, std_dev):
    return (normalized_column * std_dev) + mean


def normalize_max_min(sample, min_vals, max_vals):
    """
    use max min of entire dataset, not just the batch
    """
    # print(f'val, min_vals, max_vals {sample, min_vals, max_vals}')
    sample = (sample - min_vals) / (max_vals - min_vals)
    # return round(sample, 3)
    return sample



def show_patches(images, num_patches=25):
    # Calculate grid size (assume square grid)
    grid_size = int(np.sqrt(num_patches))
    
    # Create a figure to display the patches
    fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))
    
    for i in range(grid_size):
        for j in range(grid_size):
            idx = i * grid_size + j
            if idx < num_patches:
                # Transpose image from (3, 64, 64) to (64, 64, 3) for displaying
                print(f'images[idx] {images[idx].size()}')

                # img = np.transpose(images[idx], (1, 2, 0))
                # print(f'img {img.shape}')
                # Show the image in the corresponding subplot
                axes[i, j].imshow(images[idx].permute(1, 2, 0)) # after permute height, width, channel
                axes[i, j].axis('off')  # Hide the axes for a cleaner look

    plt.tight_layout()
    plt.show()



def count_model_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"Total number of parameters: {total_params}")
    print(f"Number of trainable parameters: {trainable_params}")